{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br0Q86U0I19R",
        "outputId": "947ab94b-4840-481e-dec8-d5cb5d904385"
      },
      "outputs": [],
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BqZN_05F_Q21",
        "outputId": "50c26e6c-db31-4295-d025-c2ae533c5c79"
      },
      "outputs": [],
      "source": [
        "!pip install tfx "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "167y_-CmUxU4"
      },
      "outputs": [],
      "source": [
        "import json \n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# your api key\n",
        "api_key = {\n",
        "'username':\"your_kaggle_username\" ,\n",
        "'key':\"your_kaggle_api_key\"}\n",
        "\n",
        "# uses pathlib Path\n",
        "kaggle_path = Path('/root/.kaggle')\n",
        "os.makedirs(kaggle_path, exist_ok=True)\n",
        "\n",
        "# opens file and dumps python dict to json object \n",
        "with open (kaggle_path/'kaggle.json', 'w') as handl:\n",
        "    json.dump(api_key,handl)\n",
        "\n",
        "os.chmod(kaggle_path/'kaggle.json', 600)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5PdFTpTUyZ5",
        "outputId": "2df28f7f-af2f-42c7-d4d7-ecd9a6b13bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            "100% 811M/812M [00:06<00:00, 127MB/s]\n",
            "100% 812M/812M [00:06<00:00, 132MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Fl4sQ3Uzxf",
        "outputId": "0c3e2309-47eb-45b0-8d74-e0f9a95b11d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/dogs-vs-cats.zip\n",
            "  inflating: /content/sampleSubmission.csv  \n",
            "  inflating: /content/test1.zip      \n",
            "  inflating: /content/train.zip      \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/dogs-vs-cats.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jED6TTLBU2s9",
        "outputId": "c4d63fc1-491c-437f-ca8e-21fe1bab8410"
      },
      "outputs": [],
      "source": [
        "!unzip /content/train.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEBOAgg0aHjW"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "runner_type = 'beam'\n",
        "pipeline_dir = '/content/tfx'\n",
        "pipeline_name = 'cat_dog'\n",
        "\n",
        "data_dir =  os.path.join(pipeline_dir, 'data')\n",
        "module_file = os.path.join(pipeline_dir, 'components', 'module.py')\n",
        "\n",
        "output_base = os.path.join(pipeline_dir, 'output', pipeline_name)\n",
        "serving_model_dir = os.path.join(output_base, pipeline_name)\n",
        "pipeline_root = os.path.join(output_base, 'pipeline_root')\n",
        "\n",
        "metadata_path = os.path.join(pipeline_root, 'metadata.sqlite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txV624_wU3XB",
        "outputId": "5d46377e-6ad4-438d-9076-cf532f57203f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote 5000 elements to TFRecord\n"
          ]
        }
      ],
      "source": [
        "import io \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "base_path = \"/content/train\"\n",
        "filenames = os.listdir(base_path)\n",
        "\n",
        "def generate_label_from_path(image_path):\n",
        "    if  image_path[15:18] == \"cat\":\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
        "        value = value.numpy() # get value of tensor\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def serialize_array(array):\n",
        "  array = tf.io.serialize_tensor(array)\n",
        "  return array\n",
        "\n",
        "def image_label_to_tf_train(image, label):\n",
        "\n",
        "    data = {\n",
        "        'raw_image' : _bytes_feature(serialize_array(image)),\n",
        "        'label' : _int64_feature(label)\n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=data))        \n",
        "\n",
        "\n",
        "tfrecord_filename = '/content/tfx/data/images.tfrecord'\n",
        "\n",
        "count = 0\n",
        "with tf.io.TFRecordWriter(tfrecord_filename) as writer:\n",
        "  for img_path in filenames[:5000]:\n",
        "    image_path = os.path.join(base_path, img_path)\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    img = cv2.resize(img,(100,100))\n",
        "\n",
        "    label = generate_label_from_path(image_path)\n",
        "    example = image_label_to_tf_train(img, label)\n",
        "    writer.write(example.SerializeToString())\n",
        "    count = count + 1\n",
        "writer.close()\n",
        "print(f\"Wrote {count} elements to TFRecord\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAprzREO_wOh"
      },
      "outputs": [],
      "source": [
        "from tfx import components\n",
        "import tensorflow_model_analysis as tfma \n",
        "from tfx.components import (ImportExampleGen, Evaluator, ExampleValidator, Pusher, SchemaGen, StatisticsGen, Trainer, Transform)\n",
        "from tfx.components.base import executor_spec\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
        "from tfx.proto import pusher_pb2, trainer_pb2\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "from tfx.proto import example_gen_pb2\n",
        "from tfx import v1 as tfx\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.orchestration import pipeline\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
        "import os\n",
        "import absl\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def init_components(data_root, module_file, serving_model_dir,\n",
        "                     training_steps=2000, eval_steps=200):\n",
        "  \n",
        "\n",
        "  output = example_gen_pb2.Output(split_config = example_gen_pb2.SplitConfig(splits=[\n",
        "            example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=6),\n",
        "            example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=2),\n",
        "            example_gen_pb2.SplitConfig.Split(name='test', hash_buckets=2)\n",
        "        ])\n",
        "  )\n",
        "        \n",
        "  example_gen = ImportExampleGen(input_base = data_root, output_config =output)\n",
        "\n",
        "  statistics_gen = StatisticsGen(examples = example_gen.outputs['examples'])\n",
        "\n",
        "  schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "\n",
        "  example_validator = ExampleValidator(statistics = statistics_gen.outputs['statistics'],schema=schema_gen.outputs['schema'])\n",
        "\n",
        "  transform = Transform(examples=example_gen.outputs['examples'],schema=schema_gen.outputs['schema'],module_file=module_file)\n",
        "\n",
        "  trainer = Trainer(module_file=(module_file),transformed_examples=transform.outputs['transformed_examples'],transform_graph=transform.outputs['transform_graph'],\n",
        "                      schema=schema_gen.outputs['schema'],train_args=trainer_pb2.TrainArgs(num_steps=training_steps),eval_args=trainer_pb2.EvalArgs(num_steps=eval_steps))\n",
        "\n",
        "  model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(type=tfx.types.standard_artifacts.ModelBlessing),\n",
        "  ) \n",
        "  \n",
        "  eval_config = tfma.EvalConfig(\n",
        "      model_specs=[tfma.ModelSpec(label_key='label')],\n",
        "      slicing_specs=[tfma.SlicingSpec()],\n",
        "      metrics_specs=[\n",
        "          tfma.MetricsSpec(metrics=[\n",
        "              tfma.MetricConfig(\n",
        "                  class_name='SparseCategoricalAccuracy',\n",
        "                  threshold=tfma.MetricThreshold(\n",
        "                      value_threshold=tfma.GenericValueThreshold(\n",
        "                          lower_bound={'value': 0.8})))\n",
        "          ])\n",
        "      ])\n",
        "  \n",
        "  evaluator = Evaluator(examples=transform.outputs['transformed_examples'],model=trainer.outputs['model'],eval_config=eval_config)\n",
        "\n",
        "  pusher = Pusher(model=trainer.outputs['model'],model_blessing=evaluator.outputs['blessing'],\n",
        "                  push_destination=pusher_pb2.PushDestination(filesystem=pusher_pb2.PushDestination.Filesystem(base_directory=serving_model_dir)))\n",
        "\n",
        "  \n",
        " \n",
        "  components=[\n",
        "          example_gen,\n",
        "          statistics_gen,\n",
        "          schema_gen,\n",
        "          example_validator,\n",
        "          transform,\n",
        "          trainer,\n",
        "          evaluator,\n",
        "          pusher,\n",
        "      ]\n",
        "\n",
        "  return components          \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aflshMzCHnu2"
      },
      "outputs": [],
      "source": [
        "import absl\n",
        "from tfx.orchestration import metadata, pipeline\n",
        "\n",
        "def init_beam_pipeline(components, pipeline_root, direct_num_workers):\n",
        "\n",
        "  absl.logging.info(\"Pipeline root set to:{}\".format(pipeline_root))\n",
        "  beam_arg =[\n",
        "      \"--direct_num_workers={}\".format(direct_num_workers),\n",
        "  ]\n",
        "\n",
        "  p = pipeline.Pipeline(\n",
        "      pipeline_name = pipeline_name,\n",
        "      pipeline_root = pipeline_root,\n",
        "      components = components,\n",
        "      enable_cache = False,\n",
        "      metadata_connection_config=metadata.sqlite_metadata_connection_config(metadata_path),\n",
        "      beam_pipeline_args=beam_arg\n",
        "  )\n",
        "  return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pYUmV57pWXZe",
        "outputId": "8231a01f-9d2a-47f2-a3f2-3e8e252a750f"
      },
      "outputs": [],
      "source": [
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
        "\n",
        "components = init_components(data_dir, module_file, serving_model_dir,\n",
        " training_steps=3000, eval_steps=2000)\n",
        "pipeline = init_beam_pipeline(components, pipeline_root, 2)\n",
        "BeamDagRunner().run(pipeline)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
